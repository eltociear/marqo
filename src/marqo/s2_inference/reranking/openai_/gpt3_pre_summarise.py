import pprint

from marqo.s2_inference.reranking.enums import ResultsFields
import threading
from typing import NamedTuple
from marqo.s2_inference.reranking.openai_.gpt3_utils import construct_context, prompt_to_essay
from marqo.s2_inference.errors import RerankerError
from marqo.s2_inference.types import Dict, List, Union


class PreSummariseArgs(NamedTuple):
    """Defaults for pre-summarisation call
    See the list of models here: https://beta.openai.com/docs/models
    """
    api_key: str
    engine: str = "text-ada-001"
    temperature: float = 0.0
    max_tokens: int = 256
    top_p: float = 1.0
    frequency_penalty: float = 0.0
    presence_penalty: float = 0.0

    def open_ai_args(self) -> dict:
        """Returns only the args that will be consumed by OpenAI API"""
        params = self._asdict()
        return params


class GptPreSummariser:
    """Summarises each document in results. Different from other GPT Rerankers
    in that a summarised version of each document is returned"""

    task_name = "gpt3-pre_summarise"

    def __init__(self, pre_summariser_properties: dict):
        try:
            self.reranker_properties = PreSummariseArgs(**pre_summariser_properties)
        except (KeyError, TypeError):
            raise RerankerError("OpenAI API Key not found in reranker properties")

    @staticmethod
    def prompt_template_pre_summarise(context: str):
        """ GPT3 prompt with text-based context. """
        return f'Background: \n{context}\n\nOne-paragraph summary:'

    def pre_summarise(self, query: str, search_result: Dict, searchable_attributes: List[str]) -> dict:
        """Analogous to rerank. Summarises each search result document.

        The difference is that, instead of a reranker_output document, the output
        is a dict of similar structure of search_result. The difference is that the
        original result dicts are replaced by a single field dict that contains the
        pre_summary output (as the "pre_summary" field).

        This method sends off a concurrent request for each result.

        Args:
            query: this may be used to give context to the summaries.
            search_result: dict
            searchable_attributes: we will use these as the fields to summarise

        Returns:
            A dict of this structure: {
                "hits": [{"pre_summary": <GPT Output>}]
            }
        """
        prompts = [
            self.prompt_template_pre_summarise(
                context=construct_context(
                    results={ResultsFields.hits: [hit, ]}, searchable_attributes=searchable_attributes,
                    content_separator=" | "
                )
            ) for hit in search_result[ResultsFields.hits]]

        summarised_results = {"hits": [None] * len(prompts)}

        def prompt_to_essay_threading(prompt, openai_args, index) -> None:
            """saves the essay generated by prompt_to_essay() into a summarised_results"""
            essay = prompt_to_essay(prompt, openai_args)
            summarised_results['hits'][index] = {"pre_summary": essay}

        threads = [threading.Thread(
            target=prompt_to_essay_threading,
            kwargs={"prompt": prompt, "openai_args": self.reranker_properties._asdict(), "index": i}
        ) for i, prompt in enumerate(prompts)]

        for th in threads:
            th.start()

        for th in threads:
            th.join()

        return summarised_results

